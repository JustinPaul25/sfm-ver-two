{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFM Forecasting Algorithm Simulation\n",
    "\n",
    "This notebook simulates the **LSTM**, **RNN**, and **Dense** neural network algorithms used in the SFM (Smart Fish Management) system for time-series forecasting.\n",
    "\n",
    "The implementation mirrors the TensorFlow.js version used in the web application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout, Flatten\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Functions to normalize data and create sequences for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    \"\"\"Normalize data to 0-1 range\"\"\"\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    range_val = max_val - min_val\n",
    "    normalized = (data - min_val) / range_val if range_val > 0 else np.zeros_like(data)\n",
    "    return normalized, min_val, max_val\n",
    "\n",
    "def denormalize_data(normalized, min_val, max_val):\n",
    "    \"\"\"Denormalize data back to original range\"\"\"\n",
    "    range_val = max_val - min_val\n",
    "    return normalized * range_val + min_val\n",
    "\n",
    "def create_sequences(data, sequence_length):\n",
    "    \"\"\"Create input sequences and targets for training\"\"\"\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        xs.append(data[i:i + sequence_length])\n",
    "        ys.append(data[i + sequence_length])\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architectures\n",
    "\n",
    "### 3.1 LSTM (Long Short-Term Memory)\n",
    "- Best for complex time series with long-term dependencies\n",
    "- 2 LSTM layers (50 units each), Dropout (0.2)\n",
    "- Highest accuracy, slower training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(sequence_length, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(sequence_length, 1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 RNN (Simple Recurrent Neural Network)\n",
    "- Balanced accuracy and speed\n",
    "- 2 SimpleRNN layers (32 units each), Dropout (0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_model(sequence_length, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        SimpleRNN(32, return_sequences=True, input_shape=(sequence_length, 1)),\n",
    "        Dropout(0.2),\n",
    "        SimpleRNN(32, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Dense (Multi-layer Perceptron)\n",
    "- Fastest training, good for simple patterns\n",
    "- Flatten + 3 Dense layers (128, 64, 32), Dropout (0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense_model(sequence_length, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(sequence_length, 1)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(data, algorithm='lstm', sequence_length=10, epochs=50, prediction_steps=7):\n",
    "    \"\"\"Train and forecast using selected algorithm\"\"\"\n",
    "    if algorithm == 'lstm':\n",
    "        model = build_lstm_model(sequence_length)\n",
    "    elif algorithm == 'rnn':\n",
    "        model = build_rnn_model(sequence_length)\n",
    "    elif algorithm == 'dense':\n",
    "        model = build_dense_model(sequence_length)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown algorithm: {algorithm}\")\n",
    "    \n",
    "    # Normalize and create sequences\n",
    "    normalized, min_val, max_val = normalize_data(data)\n",
    "    xs, ys = create_sequences(normalized, sequence_length)\n",
    "    xs = xs.reshape(-1, sequence_length, 1)\n",
    "    ys = ys.reshape(-1, 1)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(xs, ys, epochs=epochs, batch_size=32, validation_split=0.1, verbose=0)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = []\n",
    "    current_seq = normalized[-sequence_length:].copy()\n",
    "    for _ in range(prediction_steps):\n",
    "        X = current_seq.reshape(1, sequence_length, 1)\n",
    "        pred = model.predict(X, verbose=0)[0, 0]\n",
    "        predictions.append(pred)\n",
    "        current_seq = np.append(current_seq[1:], pred)\n",
    "    \n",
    "    predictions = denormalize_data(np.array(predictions), min_val, max_val)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Simulation with Sample Data\n",
    "\n",
    "Simulating fish weight growth over time (sample data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample historical data (e.g., average fish weight in grams over weeks)\n",
    "historical_data = np.array([10, 12, 15, 18, 22, 25, 30, 35, 40, 45, 50, 55, 60, 68, 75, 82, 90, 98, 108, 118])\n",
    "\n",
    "# Run forecast with LSTM\n",
    "lstm_predictions = forecast(historical_data, algorithm='lstm', epochs=30, prediction_steps=7)\n",
    "print(\"LSTM Predictions:\", lstm_predictions.round(2))\n",
    "\n",
    "# Run forecast with RNN\n",
    "rnn_predictions = forecast(historical_data, algorithm='rnn', epochs=30, prediction_steps=7)\n",
    "print(\"RNN Predictions:\", rnn_predictions.round(2))\n",
    "\n",
    "# Run forecast with Dense\n",
    "dense_predictions = forecast(historical_data, algorithm='dense', epochs=30, prediction_steps=7)\n",
    "print(\"Dense Predictions:\", dense_predictions.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "x_hist = np.arange(len(historical_data))\n",
    "x_pred = np.arange(len(historical_data), len(historical_data) + 7)\n",
    "\n",
    "plt.plot(x_hist, historical_data, 'b-o', label='Historical Data', markersize=4)\n",
    "plt.plot(x_pred, lstm_predictions, 'r--s', label='LSTM Forecast', markersize=5)\n",
    "plt.plot(x_pred, rnn_predictions, 'g--^', label='RNN Forecast', markersize=5)\n",
    "plt.plot(x_pred, dense_predictions, 'm--d', label='Dense Forecast', markersize=5)\n",
    "\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.title('SFM Forecasting Algorithm Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
